{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8fb35b7b-4ed4-4724-aad7-43f5c0a3c930",
      "metadata": {
        "id": "8fb35b7b-4ed4-4724-aad7-43f5c0a3c930",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Janus\n",
        "\n",
        "We provide a stand-alone implementation of Janus in this jupyter notebook that evaluates our 55k parameter model on the 3 protein fitness (GB1, Gifford, GFP) datasets.\n",
        "\n",
        "\n",
        "**NOTE:** For hardware optimization, we use the FlashFFTConv library in this implementation of Janus in this demo so we can only confirm that this code will run on A100, H100 GPUs or RTX 3090 and 4090. for more details on GPU requirements, please visit the (FlashFFTConv github: https://github.com/HazyResearch/flash-fft-conv)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f41d66c9-d354-409d-abc7-bf39a918ae74",
      "metadata": {
        "id": "f41d66c9-d354-409d-abc7-bf39a918ae74"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53899e6e-1ec7-45c3-a908-d605534b4629",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53899e6e-1ec7-45c3-a908-d605534b4629",
        "outputId": "265fdefc-4a02-47a7-bfd8-fd4e72617fc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.0\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee1e2082-e05c-47b3-a219-79ced2d6d9fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee1e2082-e05c-47b3-a219-79ced2d6d9fc",
        "outputId": "e2aa5d3e-38b1-4125-ffa2-752a1207fed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (7.4.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (10.0.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.1)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchaudio) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchaudio) (1.3.0)\n",
            "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install einops pandas pytest tqdm scipy pyarrow torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc33aba0-1f30-467b-aafe-b201868de447",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc33aba0-1f30-467b-aafe-b201868de447",
        "outputId": "1c038a0a-6377-4417-9c71-ea50017568d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e8b621e-52fe-4bcd-bfd7-c218630d6cdd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e8b621e-52fe-4bcd-bfd7-c218630d6cdd",
        "outputId": "793429b0-eae4-455d-def2-3c2194b9f37d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# !pip install torch==1.10.0+cpu torchvision==0.11.0+cpu torchaudio==0.10.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c07d6afd-702d-40a9-8a28-26f1df1fe351",
      "metadata": {
        "id": "c07d6afd-702d-40a9-8a28-26f1df1fe351"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f58c36ec-48dc-4901-bea6-6a6d53e751c0",
      "metadata": {
        "id": "f58c36ec-48dc-4901-bea6-6a6d53e751c0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import math\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from einops import rearrange, repeat\n",
        "from tqdm.auto import tqdm\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "dropout_fn = nn.Dropout1d\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip negative_input_processed.zip\n",
        "!unzip positive_input_processed.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsnjxqPIv7IE",
        "outputId": "9a0d4758-4652-49e1-b403-80eab9a02420"
      },
      "id": "LsnjxqPIv7IE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  negative_input_processed.zip\n",
            "   creating: negative_input_processed/\n",
            "  inflating: negative_input_processed/neg_10_16.mp3  \n",
            "  inflating: negative_input_processed/neg_01_18.mp3  \n",
            "  inflating: negative_input_processed/neg_05_03.mp3  \n",
            "  inflating: negative_input_processed/neg_07_12.mp3  \n",
            "  inflating: negative_input_processed/neg_06_18.mp3  \n",
            "  inflating: negative_input_processed/neg_06_05.mp3  \n",
            "  inflating: negative_input_processed/neg_05_11.mp3  \n",
            "  inflating: negative_input_processed/neg_03_19.mp3  \n",
            "  inflating: negative_input_processed/neg_01_10.mp3  \n",
            "  inflating: negative_input_processed/neg_06_19.mp3  \n",
            "  inflating: negative_input_processed/neg_07_09.mp3  \n",
            "  inflating: negative_input_processed/neg_05_06.mp3  \n",
            "  inflating: negative_input_processed/neg_08_11.mp3  \n",
            "  inflating: negative_input_processed/neg_10_09.mp3  \n",
            "  inflating: negative_input_processed/neg_03_12.mp3  \n",
            "  inflating: negative_input_processed/neg_03_13.mp3  \n",
            "  inflating: negative_input_processed/neg_07_17.mp3  \n",
            "  inflating: negative_input_processed/neg_07_03.mp3  \n",
            "  inflating: negative_input_processed/neg_09_14.mp3  \n",
            "  inflating: negative_input_processed/neg_04_03.mp3  \n",
            "  inflating: negative_input_processed/neg_01_15.mp3  \n",
            "  inflating: negative_input_processed/neg_08_07.mp3  \n",
            "  inflating: negative_input_processed/neg_03_05.mp3  \n",
            "  inflating: negative_input_processed/neg_10_15.mp3  \n",
            "  inflating: negative_input_processed/neg_06_01.mp3  \n",
            "  inflating: negative_input_processed/neg_04_16.mp3  \n",
            "  inflating: negative_input_processed/neg_04_02.mp3  \n",
            "  inflating: negative_input_processed/neg_04_06.mp3  \n",
            "  inflating: negative_input_processed/neg_04_13.mp3  \n",
            "  inflating: negative_input_processed/neg_01_14.mp3  \n",
            "  inflating: negative_input_processed/neg_08_10.mp3  \n",
            "  inflating: negative_input_processed/neg_02_13.mp3  \n",
            "  inflating: negative_input_processed/neg_04_12.mp3  \n",
            "  inflating: negative_input_processed/neg_09_19.mp3  \n",
            "  inflating: negative_input_processed/neg_02_01.mp3  \n",
            "  inflating: negative_input_processed/neg_06_12.mp3  \n",
            "  inflating: negative_input_processed/neg_06_15.mp3  \n",
            "  inflating: negative_input_processed/neg_04_01.mp3  \n",
            "  inflating: negative_input_processed/neg_10_20.mp3  \n",
            "  inflating: negative_input_processed/neg_03_06.mp3  \n",
            "  inflating: negative_input_processed/neg_03_01.mp3  \n",
            "  inflating: negative_input_processed/neg_09_09.mp3  \n",
            "  inflating: negative_input_processed/neg_07_06.mp3  \n",
            "  inflating: negative_input_processed/neg_09_11.mp3  \n",
            "  inflating: negative_input_processed/neg_01_06.mp3  \n",
            "  inflating: negative_input_processed/neg_06_03.mp3  \n",
            "  inflating: negative_input_processed/neg_05_08.mp3  \n",
            "  inflating: negative_input_processed/neg_09_20.mp3  \n",
            "  inflating: negative_input_processed/neg_08_09.mp3  \n",
            "  inflating: negative_input_processed/neg_01_08.mp3  \n",
            "  inflating: negative_input_processed/neg_08_18.mp3  \n",
            "  inflating: negative_input_processed/neg_01_01.mp3  \n",
            "  inflating: negative_input_processed/neg_02_16.mp3  \n",
            "  inflating: negative_input_processed/neg_03_07.mp3  \n",
            "  inflating: negative_input_processed/neg_03_03.mp3  \n",
            "  inflating: negative_input_processed/neg_10_02.mp3  \n",
            "  inflating: negative_input_processed/neg_09_06.mp3  \n",
            "  inflating: negative_input_processed/neg_07_13.mp3  \n",
            "  inflating: negative_input_processed/neg_06_14.mp3  \n",
            "  inflating: negative_input_processed/neg_07_19.mp3  \n",
            "  inflating: negative_input_processed/neg_01_07.mp3  \n",
            "  inflating: negative_input_processed/neg_10_10.mp3  \n",
            "  inflating: negative_input_processed/neg_04_10.mp3  \n",
            "  inflating: negative_input_processed/neg_08_17.mp3  \n",
            "  inflating: negative_input_processed/neg_09_13.mp3  \n",
            "  inflating: negative_input_processed/neg_03_18.mp3  \n",
            "  inflating: negative_input_processed/neg_07_05.mp3  \n",
            "  inflating: negative_input_processed/neg_02_19.mp3  \n",
            "  inflating: negative_input_processed/neg_08_12.mp3  \n",
            "  inflating: negative_input_processed/neg_02_03.mp3  \n",
            "  inflating: negative_input_processed/neg_05_04.mp3  \n",
            "  inflating: negative_input_processed/neg_01_13.mp3  \n",
            "  inflating: negative_input_processed/neg_10_19.mp3  \n",
            "  inflating: negative_input_processed/neg_10_11.mp3  \n",
            "  inflating: negative_input_processed/neg_02_04.mp3  \n",
            "  inflating: negative_input_processed/neg_08_03.mp3  \n",
            "  inflating: negative_input_processed/neg_10_08.mp3  \n",
            "  inflating: negative_input_processed/neg_03_17.mp3  \n",
            "  inflating: negative_input_processed/neg_07_16.mp3  \n",
            "  inflating: negative_input_processed/neg_05_07.mp3  \n",
            "  inflating: negative_input_processed/neg_02_18.mp3  \n",
            "  inflating: negative_input_processed/neg_03_11.mp3  \n",
            "  inflating: negative_input_processed/neg_05_15.mp3  \n",
            "  inflating: negative_input_processed/neg_07_18.mp3  \n",
            "  inflating: negative_input_processed/neg_01_11.mp3  \n",
            "  inflating: negative_input_processed/neg_08_16.mp3  \n",
            "  inflating: negative_input_processed/neg_05_01.mp3  \n",
            "  inflating: negative_input_processed/neg_06_06.mp3  \n",
            "  inflating: negative_input_processed/neg_03_04.mp3  \n",
            "  inflating: negative_input_processed/neg_05_12.mp3  \n",
            "  inflating: negative_input_processed/neg_04_20.mp3  \n",
            "  inflating: negative_input_processed/neg_01_17.mp3  \n",
            "  inflating: negative_input_processed/neg_08_13.mp3  \n",
            "  inflating: negative_input_processed/neg_10_03.mp3  \n",
            "  inflating: negative_input_processed/neg_06_08.mp3  \n",
            "  inflating: negative_input_processed/neg_06_09.mp3  \n",
            "  inflating: negative_input_processed/neg_09_03.mp3  \n",
            "  inflating: negative_input_processed/neg_06_10.mp3  \n",
            "  inflating: negative_input_processed/neg_06_13.mp3  \n",
            "  inflating: negative_input_processed/neg_10_17.mp3  \n",
            "  inflating: negative_input_processed/neg_10_13.mp3  \n",
            "  inflating: negative_input_processed/neg_07_10.mp3  \n",
            "  inflating: negative_input_processed/neg_06_20.mp3  \n",
            "  inflating: negative_input_processed/neg_01_02.mp3  \n",
            "  inflating: negative_input_processed/neg_04_14.mp3  \n",
            "  inflating: negative_input_processed/neg_06_04.mp3  \n",
            "  inflating: negative_input_processed/neg_03_10.mp3  \n",
            "  inflating: negative_input_processed/neg_01_05.mp3  \n",
            "  inflating: negative_input_processed/neg_02_07.mp3  \n",
            "  inflating: negative_input_processed/neg_10_01.mp3  \n",
            "  inflating: negative_input_processed/neg_07_02.mp3  \n",
            "  inflating: negative_input_processed/neg_04_11.mp3  \n",
            "  inflating: negative_input_processed/neg_08_05.mp3  \n",
            "  inflating: negative_input_processed/neg_02_15.mp3  \n",
            "  inflating: negative_input_processed/neg_04_18.mp3  \n",
            "  inflating: negative_input_processed/neg_06_02.mp3  \n",
            "  inflating: negative_input_processed/neg_09_18.mp3  \n",
            "  inflating: negative_input_processed/neg_09_12.mp3  \n",
            "  inflating: negative_input_processed/neg_05_14.mp3  \n",
            "  inflating: negative_input_processed/neg_10_06.mp3  \n",
            "  inflating: negative_input_processed/neg_05_02.mp3  \n",
            "  inflating: negative_input_processed/neg_05_20.mp3  \n",
            "  inflating: negative_input_processed/neg_09_15.mp3  \n",
            "  inflating: negative_input_processed/neg_08_06.mp3  \n",
            "  inflating: negative_input_processed/neg_04_17.mp3  \n",
            "  inflating: negative_input_processed/neg_02_10.mp3  \n",
            "  inflating: negative_input_processed/neg_05_05.mp3  \n",
            "  inflating: negative_input_processed/neg_02_05.mp3  \n",
            "  inflating: negative_input_processed/neg_02_06.mp3  \n",
            "  inflating: negative_input_processed/neg_02_08.mp3  \n",
            "  inflating: negative_input_processed/neg_05_13.mp3  \n",
            "  inflating: negative_input_processed/neg_07_04.mp3  \n",
            "  inflating: negative_input_processed/neg_04_04.mp3  \n",
            "  inflating: negative_input_processed/neg_05_16.mp3  \n",
            "  inflating: negative_input_processed/neg_04_07.mp3  \n",
            "  inflating: negative_input_processed/neg_02_11.mp3  \n",
            "  inflating: negative_input_processed/neg_08_08.mp3  \n",
            "  inflating: negative_input_processed/neg_04_05.mp3  \n",
            "  inflating: negative_input_processed/neg_10_07.mp3  \n",
            "  inflating: negative_input_processed/neg_09_16.mp3  \n",
            "  inflating: negative_input_processed/neg_01_19.mp3  \n",
            "  inflating: negative_input_processed/neg_09_08.mp3  \n",
            "  inflating: negative_input_processed/neg_01_16.mp3  \n",
            "  inflating: negative_input_processed/neg_03_02.mp3  \n",
            "  inflating: negative_input_processed/neg_09_07.mp3  \n",
            "  inflating: negative_input_processed/neg_08_15.mp3  \n",
            "  inflating: negative_input_processed/neg_05_10.mp3  \n",
            "  inflating: negative_input_processed/neg_01_09.mp3  \n",
            "  inflating: negative_input_processed/neg_05_09.mp3  \n",
            "  inflating: negative_input_processed/neg_08_02.mp3  \n",
            "  inflating: negative_input_processed/neg_01_12.mp3  \n",
            "  inflating: negative_input_processed/neg_08_04.mp3  \n",
            "  inflating: negative_input_processed/neg_09_10.mp3  \n",
            "  inflating: negative_input_processed/neg_07_14.mp3  \n",
            "  inflating: negative_input_processed/neg_09_02.mp3  \n",
            "  inflating: negative_input_processed/neg_10_14.mp3  \n",
            "  inflating: negative_input_processed/neg_07_08.mp3  \n",
            "  inflating: negative_input_processed/neg_06_11.mp3  \n",
            "  inflating: negative_input_processed/neg_06_16.mp3  \n",
            "  inflating: negative_input_processed/neg_05_18.mp3  \n",
            "  inflating: negative_input_processed/neg_09_01.mp3  \n",
            "  inflating: negative_input_processed/neg_08_20.mp3  \n",
            "  inflating: negative_input_processed/neg_10_12.mp3  \n",
            "  inflating: negative_input_processed/neg_07_07.mp3  \n",
            "  inflating: negative_input_processed/neg_07_11.mp3  \n",
            "  inflating: negative_input_processed/neg_03_20.mp3  \n",
            "  inflating: negative_input_processed/neg_02_02.mp3  \n",
            "  inflating: negative_input_processed/neg_01_20.mp3  \n",
            "  inflating: negative_input_processed/neg_10_18.mp3  \n",
            "  inflating: negative_input_processed/neg_06_07.mp3  \n",
            "  inflating: negative_input_processed/neg_05_19.mp3  \n",
            "  inflating: negative_input_processed/neg_08_01.mp3  \n",
            "  inflating: negative_input_processed/neg_10_04.mp3  \n",
            "  inflating: negative_input_processed/neg_04_09.mp3  \n",
            "  inflating: negative_input_processed/neg_01_03.mp3  \n",
            "  inflating: negative_input_processed/neg_03_14.mp3  \n",
            "  inflating: negative_input_processed/neg_02_09.mp3  \n",
            "  inflating: negative_input_processed/neg_02_20.mp3  \n",
            "  inflating: negative_input_processed/neg_07_20.mp3  \n",
            "  inflating: negative_input_processed/neg_09_05.mp3  \n",
            "  inflating: negative_input_processed/neg_10_05.mp3  \n",
            "  inflating: negative_input_processed/neg_07_15.mp3  \n",
            "  inflating: negative_input_processed/neg_02_17.mp3  \n",
            "  inflating: negative_input_processed/neg_03_16.mp3  \n",
            "  inflating: negative_input_processed/neg_09_04.mp3  \n",
            "  inflating: negative_input_processed/neg_02_14.mp3  \n",
            "  inflating: negative_input_processed/neg_09_17.mp3  \n",
            "  inflating: negative_input_processed/neg_03_09.mp3  \n",
            "  inflating: negative_input_processed/neg_08_19.mp3  \n",
            "  inflating: negative_input_processed/neg_07_01.mp3  \n",
            "  inflating: negative_input_processed/neg_08_14.mp3  \n",
            "  inflating: negative_input_processed/neg_04_19.mp3  \n",
            "  inflating: negative_input_processed/neg_02_12.mp3  \n",
            "  inflating: negative_input_processed/neg_01_04.mp3  \n",
            "  inflating: negative_input_processed/neg_03_15.mp3  \n",
            "  inflating: negative_input_processed/neg_06_17.mp3  \n",
            "  inflating: negative_input_processed/neg_05_17.mp3  \n",
            "  inflating: negative_input_processed/neg_03_08.mp3  \n",
            "  inflating: negative_input_processed/neg_04_15.mp3  \n",
            "  inflating: negative_input_processed/neg_04_08.mp3  \n",
            "Archive:  positive_input_processed.zip\n",
            "   creating: positive_input_processed/\n",
            "  inflating: positive_input_processed/pos_34-03.mp3  \n",
            "  inflating: positive_input_processed/pos_06-03.mp3  \n",
            "  inflating: positive_input_processed/pos_29-03.mp3  \n",
            "  inflating: positive_input_processed/pos_18-09.mp3  \n",
            "  inflating: positive_input_processed/pos_01-02.mp3  \n",
            "  inflating: positive_input_processed/pos_08-01.mp3  \n",
            "  inflating: positive_input_processed/pos_35-04.mp3  \n",
            "  inflating: positive_input_processed/pos_22-02.mp3  \n",
            "  inflating: positive_input_processed/pos_18-01.mp3  \n",
            "  inflating: positive_input_processed/pos_14-03.mp3  \n",
            "  inflating: positive_input_processed/pos_04-05.mp3  \n",
            "  inflating: positive_input_processed/pos_05-01.mp3  \n",
            "  inflating: positive_input_processed/pos_19-01.mp3  \n",
            "  inflating: positive_input_processed/pos_12-01.mp3  \n",
            "  inflating: positive_input_processed/pos_18-06.mp3  \n",
            "  inflating: positive_input_processed/pos_13-11.mp3  \n",
            "  inflating: positive_input_processed/pos_22-01.mp3  \n",
            "  inflating: positive_input_processed/pos_23-01.mp3  \n",
            "  inflating: positive_input_processed/pos_26-02.mp3  \n",
            "  inflating: positive_input_processed/pos_18-03.mp3  \n",
            "  inflating: positive_input_processed/pos_28-03.mp3  \n",
            "  inflating: positive_input_processed/pos_20-01.mp3  \n",
            "  inflating: positive_input_processed/pos_34-01.mp3  \n",
            "  inflating: positive_input_processed/pos_29-02.mp3  \n",
            "  inflating: positive_input_processed/pos_13-03.mp3  \n",
            "  inflating: positive_input_processed/pos_20-02.mp3  \n",
            "  inflating: positive_input_processed/pos_04-01.mp3  \n",
            "  inflating: positive_input_processed/pos_30-02.mp3  \n",
            "  inflating: positive_input_processed/pos_13-02.mp3  \n",
            "  inflating: positive_input_processed/pos_04-04.mp3  \n",
            "  inflating: positive_input_processed/pos_32-01.mp3  \n",
            "  inflating: positive_input_processed/pos_24-03.mp3  \n",
            "  inflating: positive_input_processed/pos_34-02.mp3  \n",
            "  inflating: positive_input_processed/pos_18-12.mp3  \n",
            "  inflating: positive_input_processed/pos_23-03.mp3  \n",
            "  inflating: positive_input_processed/pos_18-02.mp3  \n",
            "  inflating: positive_input_processed/pos_01-01.mp3  \n",
            "  inflating: positive_input_processed/pos_26-03.mp3  \n",
            "  inflating: positive_input_processed/pos_18-08.mp3  \n",
            "  inflating: positive_input_processed/pos_22-03.mp3  \n",
            "  inflating: positive_input_processed/pos_10-01.mp3  \n",
            "  inflating: positive_input_processed/pos_02-02.mp3  \n",
            "  inflating: positive_input_processed/pos_23-02.mp3  \n",
            "  inflating: positive_input_processed/pos_13-15.mp3  \n",
            "  inflating: positive_input_processed/pos_13-13.mp3  \n",
            "  inflating: positive_input_processed/pos_14-02.mp3  \n",
            "  inflating: positive_input_processed/pos_18-14.mp3  \n",
            "  inflating: positive_input_processed/pos_18-07.mp3  \n",
            "  inflating: positive_input_processed/pos_17-01.mp3  \n",
            "  inflating: positive_input_processed/pos_02-03.mp3  \n",
            "  inflating: positive_input_processed/pos_24-01.mp3  \n",
            "  inflating: positive_input_processed/pos_18-13.mp3  \n",
            "  inflating: positive_input_processed/pos_35-01.mp3  \n",
            "  inflating: positive_input_processed/pos_31-01.mp3  \n",
            "  inflating: positive_input_processed/pos_10-03.mp3  \n",
            "  inflating: positive_input_processed/pos_13-14.mp3  \n",
            "  inflating: positive_input_processed/pos_26-05.mp3  \n",
            "  inflating: positive_input_processed/pos_11-02.mp3  \n",
            "  inflating: positive_input_processed/pos_11-01.mp3  \n",
            "  inflating: positive_input_processed/pos_28-04.mp3  \n",
            "  inflating: positive_input_processed/pos_26-01.mp3  \n",
            "  inflating: positive_input_processed/pos_02-01.mp3  \n",
            "  inflating: positive_input_processed/pos_28-01.mp3  \n",
            "  inflating: positive_input_processed/pos_18-04.mp3  \n",
            "  inflating: positive_input_processed/pos_24-02.mp3  \n",
            "  inflating: positive_input_processed/pos_07-01.mp3  \n",
            "  inflating: positive_input_processed/pos_13-07.mp3  \n",
            "  inflating: positive_input_processed/pos_25-04.mp3  \n",
            "  inflating: positive_input_processed/pos_06-05.mp3  \n",
            "  inflating: positive_input_processed/pos_21-01.mp3  \n",
            "  inflating: positive_input_processed/pos_35-02.mp3  \n",
            "  inflating: positive_input_processed/pos_25-01.mp3  \n",
            "  inflating: positive_input_processed/pos_17-02.mp3  \n",
            "  inflating: positive_input_processed/pos_35-05.mp3  \n",
            "  inflating: positive_input_processed/pos_04-03.mp3  \n",
            "  inflating: positive_input_processed/pos_18-05.mp3  \n",
            "  inflating: positive_input_processed/pos_32-02.mp3  \n",
            "  inflating: positive_input_processed/pos_13-06.mp3  \n",
            "  inflating: positive_input_processed/pos_05-02.mp3  \n",
            "  inflating: positive_input_processed/pos_13-04.mp3  \n",
            "  inflating: positive_input_processed/pos_27-01.mp3  \n",
            "  inflating: positive_input_processed/pos_25-02.mp3  \n",
            "  inflating: positive_input_processed/pos_11-03.mp3  \n",
            "  inflating: positive_input_processed/pos_13-10.mp3  \n",
            "  inflating: positive_input_processed/pos_06-02.mp3  \n",
            "  inflating: positive_input_processed/pos_33-01.mp3  \n",
            "  inflating: positive_input_processed/pos_13-01.mp3  \n",
            "  inflating: positive_input_processed/pos_08-02.mp3  \n",
            "  inflating: positive_input_processed/pos_15-01.mp3  \n",
            "  inflating: positive_input_processed/pos_13-08.mp3  \n",
            "  inflating: positive_input_processed/pos_03-03.mp3  \n",
            "  inflating: positive_input_processed/pos_06-01.mp3  \n",
            "  inflating: positive_input_processed/pos_30-01.mp3  \n",
            "  inflating: positive_input_processed/pos_18-11.mp3  \n",
            "  inflating: positive_input_processed/pos_35-03.mp3  \n",
            "  inflating: positive_input_processed/pos_03-01.mp3  \n",
            "  inflating: positive_input_processed/pos_18-15.mp3  \n",
            "  inflating: positive_input_processed/pos_28-02.mp3  \n",
            "  inflating: positive_input_processed/pos_03-02.mp3  \n",
            "  inflating: positive_input_processed/pos_17-03.mp3  \n",
            "  inflating: positive_input_processed/pos_04-02.mp3  \n",
            "  inflating: positive_input_processed/pos_25-03.mp3  \n",
            "  inflating: positive_input_processed/pos_14-01.mp3  \n",
            "  inflating: positive_input_processed/pos_06-04.mp3  \n",
            "  inflating: positive_input_processed/pos_13-12.mp3  \n",
            "  inflating: positive_input_processed/pos_33-02.mp3  \n",
            "  inflating: positive_input_processed/pos_16-01.mp3  \n",
            "  inflating: positive_input_processed/pos_10-02.mp3  \n",
            "  inflating: positive_input_processed/pos_09-01.mp3  \n",
            "  inflating: positive_input_processed/pos_18-10.mp3  \n",
            "  inflating: positive_input_processed/pos_26-04.mp3  \n",
            "  inflating: positive_input_processed/pos_13-05.mp3  \n",
            "  inflating: positive_input_processed/pos_29-01.mp3  \n",
            "  inflating: positive_input_processed/pos_25-05.mp3  \n",
            "  inflating: positive_input_processed/pos_13-09.mp3  \n",
            "  inflating: positive_input_processed/pos_13-17.mp3  \n",
            "  inflating: positive_input_processed/pos_13-16.mp3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96622c5e-4cfe-46c4-8087-4d41354013b4",
      "metadata": {
        "id": "96622c5e-4cfe-46c4-8087-4d41354013b4"
      },
      "source": [
        "# Dataloader\n",
        "\n",
        "Here we provide the dataloader for the audio call prediction tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "58fef070-a21c-418e-a280-89751a713f07",
      "metadata": {
        "id": "58fef070-a21c-418e-a280-89751a713f07"
      },
      "outputs": [],
      "source": [
        "def get_audio_files_and_labels(audio_folders):\n",
        "    files_and_labels = []\n",
        "    for folder in audio_folders:\n",
        "        label = np.array([0, 1]) if \"positive\" in folder else np.array([1, 0])\n",
        "        for file in os.listdir(folder):\n",
        "            files_and_labels.append((os.path.join(folder, file), label))\n",
        "    return files_and_labels\n",
        "\n",
        "audio_folders = ['negative_input_processed', 'positive_input_processed']\n",
        "all_data = get_audio_files_and_labels(audio_folders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "115fd695-885e-41b0-9e65-0603c3d2cdae",
      "metadata": {
        "id": "115fd695-885e-41b0-9e65-0603c3d2cdae"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_pcVd7Ww9wM",
        "outputId": "8106d29a-3db4-466e-e183-056cb16aedce"
      },
      "id": "z_pcVd7Ww9wM",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "253"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "8dbace71-16bc-4da3-b764-93b05751be41",
      "metadata": {
        "id": "8dbace71-16bc-4da3-b764-93b05751be41"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, annotations, transformation, target_sample_rate, num_samples, device='cpu'):\n",
        "        self.annotations = annotations\n",
        "        self.transformation = transformation.to(device)\n",
        "        self.target_sample_rate = target_sample_rate\n",
        "        self.num_samples = num_samples\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        audio_sample_path, label = self.annotations[index]\n",
        "        # print(audio_sample_path)\n",
        "        signal, sr = torchaudio.load(audio_sample_path)\n",
        "        signal = signal.to(self.device)\n",
        "        if sr != self.target_sample_rate:\n",
        "            # raise Exception(f\"Sample rate {sr} is not {self.target_sample_rate}.\")\n",
        "            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.target_sample_rate).to(self.device)\n",
        "            signal = resampler(signal)\n",
        "        # print(signal.shape)\n",
        "        if signal.shape[0] > 1:\n",
        "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
        "        if signal.shape[1] > self.num_samples:\n",
        "            signal = signal[:, :self.num_samples]\n",
        "        elif signal.shape[1] < self.num_samples:\n",
        "            padding = self.num_samples - signal.shape[1]\n",
        "            signal = torch.cat([signal, torch.zeros(1, padding).to(self.device)], dim=1)\n",
        "        signal = self.transformation(signal)\n",
        "        return torch.squeeze(signal.permute(0, 2, 1)), label\n",
        "\n",
        "# Example usage\n",
        "transformation = torchaudio.transforms.Spectrogram()\n",
        "target_sample_rate = 16000  # Define according to your needs\n",
        "num_samples = target_sample_rate * 15  # 15 seconds of audio\n",
        "\n",
        "train_dataset = AudioDataset(train_data, transformation, target_sample_rate, num_samples)\n",
        "test_dataset = AudioDataset(test_data, transformation, target_sample_rate, num_samples)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples, labels = next(iter(train_loader))\n",
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAQlqcfE0BFf",
        "outputId": "544bbaea-5b78-4da3-f53c-a3c3a3e65ae1"
      },
      "id": "LAQlqcfE0BFf",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2070293d-b738-48f6-b61a-e6f8c6e3fc35",
      "metadata": {
        "id": "2070293d-b738-48f6-b61a-e6f8c6e3fc35"
      },
      "source": [
        "# RMSNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "c890f140-ea20-4592-ab69-0778a781a41e",
      "metadata": {
        "id": "c890f140-ea20-4592-ab69-0778a781a41e"
      },
      "outputs": [],
      "source": [
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, d, p=-1., eps=1e-8, bias=False):\n",
        "        \"\"\"\n",
        "            Root Mean Square Layer Normalization\n",
        "        :param d: model size\n",
        "        :param p: partial RMSNorm, valid value [0, 1], default -1.0 (disabled)\n",
        "        :param eps:  epsilon value, default 1e-8\n",
        "        :param bias: whether use bias term for RMSNorm, disabled by\n",
        "            default because RMSNorm doesn't enforce re-centering invariance.\n",
        "        \"\"\"\n",
        "        super(RMSNorm, self).__init__()\n",
        "\n",
        "        self.eps = eps\n",
        "        self.d = d\n",
        "        self.p = p\n",
        "        self.bias = bias\n",
        "\n",
        "        self.scale = nn.Parameter(torch.ones(d))\n",
        "        self.register_parameter(\"scale\", self.scale)\n",
        "\n",
        "        if self.bias:\n",
        "            self.offset = nn.Parameter(torch.zeros(d))\n",
        "            self.register_parameter(\"offset\", self.offset)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.p < 0. or self.p > 1.:\n",
        "            norm_x = x.norm(2, dim=-1, keepdim=True)\n",
        "            d_x = self.d\n",
        "        else:\n",
        "            partial_size = int(self.d * self.p)\n",
        "            partial_x, _ = torch.split(x, [partial_size, self.d - partial_size], dim=-1)\n",
        "\n",
        "            norm_x = partial_x.norm(2, dim=-1, keepdim=True)\n",
        "            d_x = partial_size\n",
        "\n",
        "        rms_x = norm_x * d_x ** (-1. / 2)\n",
        "        x_normed = x / (rms_x + self.eps)\n",
        "\n",
        "        if self.bias:\n",
        "            return self.scale * x_normed + self.offset\n",
        "\n",
        "        return self.scale * x_normed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f70d493a-4230-4371-976a-2429006cdc42",
      "metadata": {
        "id": "f70d493a-4230-4371-976a-2429006cdc42"
      },
      "source": [
        "# S4D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "b64c2fa3-d434-404b-be49-e5d6cff382df",
      "metadata": {
        "id": "b64c2fa3-d434-404b-be49-e5d6cff382df"
      },
      "outputs": [],
      "source": [
        "class DropoutNd(nn.Module):\n",
        "    def __init__(self, p: float = 0.5, tie=True, transposed=True):\n",
        "        \"\"\"\n",
        "        tie: tie dropout mask across sequence lengths (Dropout1d/2d/3d)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        if p < 0 or p >= 1:\n",
        "            raise ValueError(\"dropout probability has to be in [0, 1), \" \"but got {}\".format(p))\n",
        "        self.p = p\n",
        "        self.tie = tie\n",
        "        self.transposed = transposed\n",
        "        self.binomial = torch.distributions.binomial.Binomial(probs=1-self.p)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"X: (batch, dim, lengths...).\"\"\"\n",
        "        if self.training:\n",
        "            if not self.transposed: X = rearrange(X, 'b ... d -> b d ...')\n",
        "            # binomial = torch.distributions.binomial.Binomial(probs=1-self.p) # This is incredibly slow because of CPU -> GPU copying\n",
        "            mask_shape = X.shape[:2] + (1,)*(X.ndim-2) if self.tie else X.shape\n",
        "            # mask = self.binomial.sample(mask_shape)\n",
        "            mask = torch.rand(*mask_shape, device=X.device) < 1.-self.p\n",
        "            X = X * mask * (1.0/(1-self.p))\n",
        "            if not self.transposed: X = rearrange(X, 'b d ... -> b ... d')\n",
        "            return X\n",
        "        return X\n",
        "\n",
        "class S4DKernel(nn.Module):\n",
        "    \"\"\"Generate convolution kernel from diagonal SSM parameters.\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, N=64, dt_min=0.001, dt_max=0.1, lr=None):\n",
        "        super().__init__()\n",
        "        # Generate dt\n",
        "        H = d_model\n",
        "        log_dt = torch.rand(H) * (\n",
        "            math.log(dt_max) - math.log(dt_min)\n",
        "        ) + math.log(dt_min)\n",
        "\n",
        "        C = torch.randn(H, N // 2, dtype=torch.cfloat)\n",
        "        self.C = nn.Parameter(torch.view_as_real(C))\n",
        "        self.register(\"log_dt\", log_dt, lr)\n",
        "\n",
        "        log_A_real = torch.log(0.5 * torch.ones(H, N//2))\n",
        "        A_imag = math.pi * repeat(torch.arange(N//2), 'n -> h n', h=H)\n",
        "        self.register(\"log_A_real\", log_A_real, lr)\n",
        "        self.register(\"A_imag\", A_imag, lr)\n",
        "\n",
        "    def forward(self, L):\n",
        "        \"\"\"\n",
        "        returns: (..., c, L) where c is number of channels (default 1)\n",
        "        \"\"\"\n",
        "\n",
        "        # Materialize parameters\n",
        "        dt = torch.exp(self.log_dt) # (H)\n",
        "        C = torch.view_as_complex(self.C) # (H N)\n",
        "        A = -torch.exp(self.log_A_real) + 1j * self.A_imag # (H N)\n",
        "\n",
        "        # Vandermonde multiplication\n",
        "        dtA = A * dt.unsqueeze(-1)  # (H N)\n",
        "        K = dtA.unsqueeze(-1) * torch.arange(L, device=A.device) # (H N L)\n",
        "        C = C * (torch.exp(dtA)-1.) / A\n",
        "        K = 2 * torch.einsum('hn, hnl -> hl', C, torch.exp(K)).real\n",
        "\n",
        "        return K\n",
        "\n",
        "    def register(self, name, tensor, lr=None):\n",
        "        \"\"\"Register a tensor with a configurable learning rate and 0 weight decay\"\"\"\n",
        "\n",
        "        if lr == 0.0:\n",
        "            self.register_buffer(name, tensor)\n",
        "        else:\n",
        "            self.register_parameter(name, nn.Parameter(tensor))\n",
        "\n",
        "            optim = {\"weight_decay\": 0.0}\n",
        "            if lr is not None: optim[\"lr\"] = lr\n",
        "            setattr(getattr(self, name), \"_optim\", optim)\n",
        "\n",
        "\n",
        "class S4D(nn.Module):\n",
        "    def __init__(self, d_model, d_state=64, dropout=0.0, transposed=True, **kernel_args):\n",
        "        super().__init__()\n",
        "\n",
        "        self.h = d_model\n",
        "        self.n = d_state\n",
        "        self.d_output = self.h\n",
        "        self.transposed = transposed\n",
        "\n",
        "        self.D = nn.Parameter(torch.randn(self.h))\n",
        "\n",
        "        # SSM Kernel\n",
        "        self.kernel = S4DKernel(self.h, N=self.n, **kernel_args)\n",
        "\n",
        "        # Pointwise\n",
        "        self.activation = nn.GELU()\n",
        "        # dropout_fn = nn.Dropout2d # NOTE: bugged in PyTorch 1.11\n",
        "        dropout_fn = DropoutNd\n",
        "        self.dropout = dropout_fn(dropout) if dropout > 0.0 else nn.Identity()\n",
        "\n",
        "        # position-wise output transform to mix features\n",
        "        self.output_linear = nn.Sequential(\n",
        "            nn.Conv1d(self.h, 2*self.h, kernel_size=1),\n",
        "            nn.GLU(dim=-2),\n",
        "        )\n",
        "\n",
        "    def forward(self, u, **kwargs): # absorbs return_output and transformer src mask\n",
        "        \"\"\" Input and output shape (B, H, L) \"\"\"\n",
        "        if not self.transposed: u = u.transpose(-1, -2)\n",
        "        L = u.size(-1)\n",
        "\n",
        "        # Compute SSM Kernel\n",
        "        k = self.kernel(L=L) # (H L)\n",
        "\n",
        "        # Convolution\n",
        "        k_f = torch.fft.rfft(k, n=2*L) # (H L)\n",
        "        u_f = torch.fft.rfft(u, n=2*L) # (B H L)\n",
        "        y = torch.fft.irfft(u_f*k_f, n=2*L)[..., :L] # (B H L)\n",
        "\n",
        "        # Compute D term in state space equation - essentially a skip connection\n",
        "        y = y + u * self.D.unsqueeze(-1)\n",
        "\n",
        "        y = self.dropout(self.activation(y))\n",
        "        y = self.output_linear(y)\n",
        "        if not self.transposed: y = y.transpose(-1, -2)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2adfea6-e8c3-4eba-8c11-2b147a8cf200",
      "metadata": {
        "id": "c2adfea6-e8c3-4eba-8c11-2b147a8cf200"
      },
      "source": [
        "# Janus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "c651f042-6cf4-4300-92e5-dfcb736ca028",
      "metadata": {
        "id": "c651f042-6cf4-4300-92e5-dfcb736ca028"
      },
      "outputs": [],
      "source": [
        "class Janus(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_input,\n",
        "        d_output=10,\n",
        "        d_model=256,\n",
        "        n_layers=4,\n",
        "        dropout=0.2,\n",
        "        prenorm=True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Linear encoder\n",
        "        self.encoder = nn.Linear(d_input, d_model)\n",
        "        self.prenorm = prenorm\n",
        "\n",
        "        # Stack S4 layers as residual blocks\n",
        "        self.s4_layers = nn.ModuleList()\n",
        "        self.norms = nn.ModuleList()\n",
        "        self.dropouts = nn.ModuleList()\n",
        "        for _ in range(n_layers):\n",
        "            self.s4_layers.append(\n",
        "                S4D(d_model, dropout=dropout, transposed=True, lr=min(0.001, 0.002))\n",
        "            )\n",
        "            self.norms.append(RMSNorm(d_model))\n",
        "            self.dropouts.append(dropout_fn(dropout))\n",
        "\n",
        "        # Linear decoder\n",
        "        self.decoder = nn.Linear(d_model, d_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Input x is shape (B, L, d_input)\n",
        "        \"\"\"\n",
        "        x = self.encoder(x)  # (B, L, d_input) -> (B, L, d_model)\n",
        "        #print(x.shape)\n",
        "        x = x.transpose(-1, -2)  # (B, L, d_model) -> (B, d_model, L)\n",
        "        for layer, norm, dropout in zip(self.s4_layers, self.norms, self.dropouts):\n",
        "            # Each iteration of this loop will map (B, d_model, L) -> (B, d_model, L)\n",
        "            z = x\n",
        "            if self.prenorm:\n",
        "                # Prenorm\n",
        "                z = norm(z.transpose(-1, -2)).transpose(-1, -2)\n",
        "\n",
        "            # Apply S4 block: we ignore the state input and output\n",
        "            z = layer(z)\n",
        "\n",
        "            # Dropout on the output of the S4 block\n",
        "            z = dropout(z)\n",
        "\n",
        "            # Residual connection\n",
        "            x = z + x\n",
        "\n",
        "            if not self.prenorm:\n",
        "                # Postnorm\n",
        "                x = norm(x.transpose(-1, -2)).transpose(-1, -2)\n",
        "\n",
        "        x = x.transpose(-1, -2)\n",
        "\n",
        "        # Pooling: average pooling over the sequence length\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        # Decode the outputs\n",
        "        x = self.decoder(x)  # (B, d_model) -> (B, d_output)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16f9ba1f-0535-443b-9348-7d2984810386",
      "metadata": {
        "id": "16f9ba1f-0535-443b-9348-7d2984810386"
      },
      "source": [
        "# Model Instantiation\n",
        "\n",
        "This model instantiation is provided as a sanity check, the training loop in the next section will instantiate a new model for each task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "b4ecc528-179b-4fb5-b343-8ab9e9819a4b",
      "metadata": {
        "id": "b4ecc528-179b-4fb5-b343-8ab9e9819a4b"
      },
      "outputs": [],
      "source": [
        "model_config = dict(\n",
        "    d_model=32,\n",
        "    n_layers=1,\n",
        "    dropout=0.2,\n",
        "    d_input=201, #input dim\n",
        "    d_output=2, #num classes\n",
        "    prenorm=True,\n",
        ")\n",
        "\n",
        "d_model = model_config['d_model']\n",
        "n_layers = model_config['n_layers']\n",
        "\n",
        "model = Janus(**model_config).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "ebe3d560-7e4d-424a-b67d-fa895c7423b7",
      "metadata": {
        "id": "ebe3d560-7e4d-424a-b67d-fa895c7423b7",
        "outputId": "3fa06f3c-1c0f-49be-ea32-f60a45a08bf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Janus(\n",
            "  (encoder): Linear(in_features=201, out_features=32, bias=True)\n",
            "  (s4_layers): ModuleList(\n",
            "    (0): S4D(\n",
            "      (kernel): S4DKernel()\n",
            "      (activation): GELU(approximate='none')\n",
            "      (dropout): DropoutNd()\n",
            "      (output_linear): Sequential(\n",
            "        (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
            "        (1): GLU(dim=-2)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norms): ModuleList(\n",
            "    (0): RMSNorm()\n",
            "  )\n",
            "  (dropouts): ModuleList(\n",
            "    (0): Dropout1d(p=0.2, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=32, out_features=2, bias=True)\n",
            ")\n",
            "Total trainable parameters: 12834\n"
          ]
        }
      ],
      "source": [
        "# Print model architecture\n",
        "print(model)\n",
        "\n",
        "# Count total trainable parameters\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters: {num_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample, label = next(iter(train_loader))\n",
        "outputs = model(sample.to(device))"
      ],
      "metadata": {
        "id": "lRbrc3Ii4exy"
      },
      "id": "lRbrc3Ii4exy",
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.log_softmax(dim=1).exp()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyhWoSfD4n8V",
        "outputId": "1045136b-6655-41e5-998a-e281376feee6"
      },
      "id": "kyhWoSfD4n8V",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7.4372e-01, 2.5628e-01],\n",
              "        [6.9853e-01, 3.0147e-01],\n",
              "        [8.1746e-01, 1.8254e-01],\n",
              "        [7.0092e-01, 2.9908e-01],\n",
              "        [7.3801e-01, 2.6199e-01],\n",
              "        [9.9960e-01, 3.9687e-04],\n",
              "        [6.0693e-01, 3.9307e-01],\n",
              "        [8.8141e-01, 1.1859e-01],\n",
              "        [9.9890e-01, 1.0966e-03],\n",
              "        [6.9760e-01, 3.0240e-01],\n",
              "        [5.4452e-01, 4.5548e-01],\n",
              "        [6.1720e-01, 3.8280e-01],\n",
              "        [5.7418e-01, 4.2582e-01],\n",
              "        [7.8751e-01, 2.1249e-01],\n",
              "        [7.4590e-01, 2.5410e-01],\n",
              "        [6.8831e-01, 3.1169e-01]], device='cuda:0', grad_fn=<ExpBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXt3M90c4uQz",
        "outputId": "b1ed1c50-35ab-4146-ed61-1f4361ed8f77"
      },
      "id": "aXt3M90c4uQz",
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd72d72e-a6ee-4943-9cda-e8e53ebba8a8",
      "metadata": {
        "id": "cd72d72e-a6ee-4943-9cda-e8e53ebba8a8"
      },
      "source": [
        "# Training and Evaluation Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "nTMYS4ah1eOO",
      "metadata": {
        "id": "nTMYS4ah1eOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1605fe3e-1877-43cc-943a-fbd4335fb6a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: Train Acc: 0.9881, Val Acc: 0.9844, Loss: 0.0036: 100%|██████████| 20/20 [01:54<00:00,  5.74s/it]\n"
          ]
        }
      ],
      "source": [
        "# Here is the updated train loop for binary classfication:\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "# Assuming you have defined the model, dataloaders, and other necessary components above\n",
        "\n",
        "# Set the number of epochs\n",
        "num_epochs = 20\n",
        "best_loss = 5\n",
        "\n",
        "# Initialize the model\n",
        "model = Janus(**model_config).to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "\n",
        "pbar = tqdm(range(num_epochs), desc=f\"Epoch 0: Train Acc: 0.0000, Val Acc: 0.0000, Loss: 0.0000\")\n",
        "for epoch in pbar:\n",
        "    # Lists for storing metrics\n",
        "    train_labels_list, train_outputs_list = [], []\n",
        "    val_labels_list, val_outputs_list = [], []\n",
        "\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    for sequences, labels in train_loader:\n",
        "        sequences = sequences.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(sequences)\n",
        "        # print(outputs)\n",
        "        # argmax to get the output\n",
        "        outputs = logits.log_softmax(dim=1).exp()\n",
        "        # outputs = torch.argmax(outputs, dim=1, keepdim=True).float()\n",
        "        # Calculate loss\n",
        "        labels = labels.float()\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store outputs and labels for calculating metrics\n",
        "        outputs = torch.argmax(outputs, dim=1, keepdim=True)\n",
        "        labels = torch.argmax(labels, dim=1, keepdim=True)\n",
        "        train_outputs_list.append(outputs.detach().cpu().numpy())\n",
        "        train_labels_list.append(labels.detach().cpu().numpy())\n",
        "\n",
        "    # Calculate training accuracy and AUC\n",
        "    train_outputs = np.vstack(train_outputs_list)\n",
        "    train_labels = np.vstack(train_labels_list)\n",
        "    train_acc = (train_outputs == train_labels).sum().item() / train_outputs.shape[0]\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels in test_loader:\n",
        "            sequences = sequences.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits = model(sequences)\n",
        "            outputs = logits.log_softmax(dim=1).exp()\n",
        "            outputs = torch.argmax(outputs, dim=1, keepdim=True)\n",
        "            labels = torch.argmax(labels, dim=1, keepdim=True)\n",
        "            # Store outputs and labels for calculating metrics\n",
        "            val_outputs_list.append(outputs.cpu().numpy())\n",
        "            val_labels_list.append(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate validation accuracy and AUC\n",
        "    val_outputs = np.vstack(val_outputs_list)\n",
        "    val_labels = np.vstack(val_labels_list)\n",
        "    val_acc = (val_outputs == val_labels).sum().item() / val_outputs.shape[0]\n",
        "\n",
        "    # Update best AUC and save the model if improved\n",
        "    if loss.item() < best_loss:\n",
        "        best_loss = loss.item()\n",
        "        torch.save(model.state_dict(), f'Janus_{d_model}_{n_layers}.pt')\n",
        "\n",
        "    pbar.set_description(f\"Epoch {epoch}: Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# model.load_state_dict(torch.load(\"INSERT FILENAME.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "27Zh8_JS1h9H"
      },
      "id": "27Zh8_JS1h9H",
      "execution_count": 122,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "pytorch-gpu",
      "language": "python",
      "name": "pytorch-gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}